{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd589cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio_file_path='/Users/saumitkale/Downloads/UrbanSound8K/audio/fold5/100263-2-0-3.wav'\n",
    "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)\n",
    "\n",
    "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfccs.shape)\n",
    "\n",
    "mfccs\n",
    "\n",
    "audio_dataset_path='/Users/saumitkale/Downloads/UrbanSound8K/audio/'\n",
    "metadata=pd.read_csv('/Users/saumitkale/Downloads/UrbanSound8K/metadata/UrbanSound8k.csv')\n",
    "metadata.head()\n",
    "\n",
    "\n",
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features\n",
    "    \n",
    "    \n",
    "extracted_features=[]\n",
    "\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])\n",
    "    \n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()\n",
    "\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())\n",
    "\n",
    "X.shape\n",
    "\n",
    "y\n",
    "\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))\n",
    "\n",
    "y\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "X_train\n",
    "\n",
    "y\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "X_test.shape\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "y_test.shape\n",
    "\n",
    "\n",
    "num_labels=y.shape[1]\n",
    "\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "\n",
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])\n",
    "\n",
    "\n",
    "X_test[1]\n",
    "\n",
    "model.predict_classes(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/saumitkale/Downloads/UrbanSound8K/dog-bark.mp3\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast')\n",
    "\n",
    "audio = audio.ravel()\n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features = mfccs_scaled_features.reshape(1, -1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "\n",
    "predicted_label = np.argmax(model.predict(mfccs_scaled_features), axis=-1)\n",
    "print(predicted_label)\n",
    "\n",
    "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
    "print(prediction_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756a30b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
